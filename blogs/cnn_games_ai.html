<!doctype html>


<link href="https://fonts.googleapis.com/css?family=Cardo&display=swap" rel="stylesheet"> 

<link rel="stylesheet" href="../css/bootstrap.min.css"></link>
<!--
<link rel="stylesheet" href="/css/compiled-4.8.0.min.css"></link>
-->
<script type="text/javascript"  src="../js/bootstrap.min.js"></script>

<script type="text/javascript"  src="../js/jquery-3.2.1.slim.min.js"></script>
<script type="text/javascript"  src="../js/popper.min.js"></script>


<link rel='stylesheet' id='wsl-widget-css'  href='https://mdbootstrap.com/wp-content/plugins/wordpress-social-login/assets/css/style.css?ver=5.1.1' type='text/css' media='all' />

<link rel='stylesheet' id='compiled.css-css'  href='https://mdbootstrap.com/wp-content/themes/mdbootstrap4/css/compiled-4.8.0.min.css?ver=4.8.0' type='text/css' media='all' />


<link rel="shortcut icon" type="image/x-icon" href="../img/thumbnail.jpg">


<!-- Bootstrap core CSS -->

<link href="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/4.3.1/css/bootstrap.min.css" rel="stylesheet">

<!-- Material Design Bootstrap -->

<link href="https://cdnjs.cloudflare.com/ajax/libs/mdbootstrap/4.8.0/css/mdb.min.css" rel="stylesheet">



<!-- Bootstrap core JavaScript -->

<script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/4.3.1/js/bootstrap.min.js"></script>


<!-- Lazy loading of Gallery and stuffs!-->

<script src="../js/jimjs.js"></script>
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/normalize/7.0.0/normalize.min.css">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.2/css/all.css" integrity="sha256-46qynGAkLSFpVbEBog43gvNhfrOj+BmwXdxFgVK/Kvc=" crossorigin="anonymous" /> 

<link rel = "stylesheet" type = "text/css" href = "../css/jimstyle.css" />

<html>
  <head>
    <meta charset="utf-8">
    
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="author" content="Jimut Bahan Pal" />
    <meta name="description" content="Personal website">
    <meta name="google-site-verification" content="2SC5t4-rLXOS1eAW-l2YL_qFLuIJW2vSRZNduyOGKN0" />
    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-140291358-1"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'UA-140291358-1');
    </script>

    
    <title> CNN AI </title>
  </head>

  <body onload = "myFunction()">
    <div id="loading"> </div>
    
    <!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Theme Toggle Example</title>
    <link rel="stylesheet" type="text/css" href="../css/jimstyle.css" />

    <style>
        /* Define light theme */
        :root {
            --background-color: #ffffff;
            --text-color: #000000;
            --container-bg: #ffffff;
            --container-text: #000000;
            --special-color: #0076f4;
            --navbar-bg: rgba(255, 255, 255, 0);
            --navbar-backdrop: blur(2px);
            --toggler-glow-color: #18a236; /* Green glow color */
        }

        /* Define dark theme */
        [data-theme="dark"] {
            --background-color: #413f3f;
            --text-color: #ffffff;
            --container-bg: #413f3f;
            --container-text: #ffffff;
            --special-color: #bb86fc;
            --navbar-bg: rgba(65, 63, 63, 0.5);
            --navbar-backdrop: blur(2px);
            --toggler-glow-color: #18a236; /* Same green glow in dark mode */
        }

        /* Apply themes to the body and all elements */
        body {
            background-color: var(--background-color);
            color: var(--text-color);
            transition: background-color 0.5s, color 0.5s;
        }

        /* Updated navbar styling */
        .navbar {
            background-color: var(--navbar-bg) !important;
            backdrop-filter: var(--navbar-backdrop);
            -webkit-backdrop-filter: var(--navbar-backdrop);
            transition: all 0.5s ease;
            border-bottom: 1px solid rgba(255, 255, 255, 0.1);
        }

        /* Ensure navbar text is visible in both themes */
        .navbar .nav-link {
            color: var(--text-color) !important;
        }

        /* Updated active link styling */
        .navbar ul li.active a, 
        .navbar ul li a:hover {
            background-color: rgba(229, 232, 209, 0.3);
            font-weight: bold;
        }

        /* Container styling */
        body div {
            background-color: var(--container-bg);
            color: var(--container-text);
            transition: background-color 0.5s, color 0.5s;
        }

        /* Override specific colors for dark theme */
        [data-theme="dark"] .btn-primary,
        [data-theme="dark"] .bg-primary,
        [data-theme="dark"] .text-primary {
            background-color: var(--special-color) !important;
            color: var(--container-text) !important;
        }

        #theme-icon {
            font-size: 2em;
        }

        /* Make navbar container transparent */
        .navbar .container {
            background-color: transparent !important;
        }

        /* NAVBAR TOGGLER GLOW EFFECT */
        @keyframes glowing-toggler {
            0% { box-shadow: 0 0 5px var(--toggler-glow-color); }
            50% { box-shadow: 0 0 20px var(--toggler-glow-color), 0 0 30px var(--toggler-glow-color); }
            100% { box-shadow: 0 0 5px var(--toggler-glow-color); }
        }

        /* Apply animation only when toggler is visible (on smaller screens) */
        @media (max-width: 991.98px) {
            .navbar-toggler {
                animation: glowing-toggler 2s infinite;
                border-color: var(--toggler-glow-color) !important;
            }
            
            /* Style the toggler icon bars with the same green color */
            .navbar-toggler-icon {
                background-image: url("data:image/svg+xml,%3csvg xmlns='http://www.w3.org/2000/svg' width='30' height='30' viewBox='0 0 30 30'%3e%3cpath stroke='rgba(24, 162, 54, 1)' stroke-linecap='round' stroke-miterlimit='10' stroke-width='2' d='M4 7h22M4 15h22M4 23h22'/%3e%3c/svg%3e") !important;
            }
        }
    </style>
</head>
<body>

<nav class="navbar navbar-icon-top navbar-expand-lg navbar-light sticky-top">
    <a class="navbar-brand" style="font-family: Georgia, Times, Times New Roman, serif;">
        <button id="theme-toggle" class="btn btn-link p-0" style="color: inherit;">
            <span id="theme-icon">🌞</span>
        </button>
    </a>

    <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarSupportedContent" 
    aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
        <span class="navbar-toggler-icon"></span>
    </button>

    <div class="collapse navbar-collapse" id="navbarSupportedContent">
        <ul class="navbar-nav mr-auto navbar-center" style="font-family: Georgia, Times, Times New Roman, serif;">
            
                <li class="nav-item">
                    <div class="container pull-left">
                        <a href="/"  class="nav-link">
                            
                                <img src="/img/icons/home.svg" alt="icon" height="25px" width="25px">
                            
                            <span size="4px" style="color: #18a236;">HOME </span>
                        </a>
                    </div>
                </li>
            
                <li class="nav-item">
                    <div class="container pull-left">
                        <a href="/publications.html"  class="nav-link">
                            
                                <img src="/img/icons/publications.png" alt="icon" height="25px" width="25px">
                            
                            <span size="4px" style="color: #18a236;">PUBLICATIONS </span>
                        </a>
                    </div>
                </li>
            
                <li class="nav-item">
                    <div class="container pull-left">
                        <a href="/blog.html"  class="nav-link">
                            
                                <img src="/img/icons/blog.svg" alt="icon" height="25px" width="25px">
                            
                            <span size="4px" style="color: #18a236;">BLOG </span>
                        </a>
                    </div>
                </li>
            
                <li class="nav-item">
                    <div class="container pull-left">
                        <a href="/projects.html"  class="nav-link">
                            
                                <img src="/img/icons/projects.jpg" alt="icon" height="25px" width="25px">
                            
                            <span size="4px" style="color: #18a236;">PROJECTS </span>
                        </a>
                    </div>
                </li>
            
                <li class="nav-item">
                    <div class="container pull-left">
                        <a href="/gallery.html"  class="nav-link">
                            
                                <img src="/img/icons/gallery.png" alt="icon" height="25px" width="25px">
                            
                            <span size="4px" style="color: #18a236;">GALLERY </span>
                        </a>
                    </div>
                </li>
            
                <li class="nav-item">
                    <div class="container pull-left">
                        <a href="/random.html"  class="nav-link">
                            
                                <img src="/img/icons/certificates.png" alt="icon" height="25px" width="25px">
                            
                            <span size="4px" style="color: #18a236;">RANDOM </span>
                        </a>
                    </div>
                </li>
            
                <li class="nav-item">
                    <div class="container pull-left">
                        <a href="/search/"  class="nav-link">
                            
                                <img src="/img/icons/search.png" alt="icon" height="25px" width="25px">
                            
                            <span size="4px" style="color: #18a236;">SEARCH </span>
                        </a>
                    </div>
                </li>
            
        </ul>
    </div>
</nav>

<script>
    const toggleButton = document.getElementById('theme-toggle');
    const themeIcon = document.getElementById('theme-icon');
    const body = document.body;

    const currentTheme = localStorage.getItem('theme');
    if (currentTheme) {
        body.setAttribute('data-theme', currentTheme);
        themeIcon.textContent = currentTheme === 'dark' ? '🌜' : '🌞';
    } else {
        body.setAttribute('data-theme', 'light');
        themeIcon.textContent = '🌞';
    }

    toggleButton.addEventListener('click', () => {
        const currentTheme = body.getAttribute('data-theme');
        const newTheme = currentTheme === 'light' ? 'dark' : 'light';
        body.setAttribute('data-theme', newTheme);
        localStorage.setItem('theme', newTheme);
        themeIcon.textContent = newTheme === 'dark' ? '🌜' : '🌞';
    });
</script>

<script type="text/javascript">
    $(function() {
        var url = window.location.href;
        $(".navbar a").each(function() {
            if (url == (this.href)) {
                $(this).closest("li").addClass("active");
                $(this).closest("li").parent().parent().addClass("active");
            }
        });
    });        
</script>

</body>
</html>

    <div align="center">  
      <br><br>
      
      <link rel = "stylesheet" type = "text/css" href = "../css/jimstyle.css" />


<br>

<h1>
    <b id="heading-font">  <img src="blog_img/cnn_ai/trex.gif"  alt="watson GIF"height="40px" width="55px"> Playing a class of games using CNN</b>
</h1>

<span class="keywords-orangered"> &nbsp; CNN &nbsp; </span>
&nbsp;&nbsp;
<span class="keywords-blue"> &nbsp; Dino Game &nbsp;</span>
&nbsp;&nbsp;
<span class="keywords-green">&nbsp; Deep Learning &nbsp;</span>
&nbsp;&nbsp;
<span class="keywords-yellow">&nbsp; Keras &nbsp;</span>
&nbsp;&nbsp;
<span class="keywords-orange">&nbsp; Tensorflow &nbsp;</span>
&nbsp;&nbsp;
<span class="keywords-deepblue">&nbsp; AI &nbsp;</span> 

<br> <br>

[<a href="../files/JBP_SCRIPTS/JBP_008.pdf" alt="pdf slide" target="_blank"> Slide PDF </a>] 



<div id="pad-container">
    <div  align="center" id="exp-font">
            <div class="container" align="justify">
                <h3> Introduction </h3>
                <br>
                Convolutional Neural Network (CNN) can do a lot of things that were previously considered almost impossible (I am taking about 1960's here).
                After the invention of CNN for digit recognition by <em> Yann Lee Cunn et al. </em>, deep learning and Machine learning have gained a tremendous boost
                in almost every nook and corner of IT industry. Machine Learning is itself a very old topic, but earlier, there were no computational power to manifest
                such enormous computation and store such huge quantities of data. Due to the growth of hardware technologies (and constant growth by Moore's Law), there is
                a huge demand for this subject in recent industry. A person who is qualified enough to solve Machine Learning tasks are paid almost double, to those who
                are just software engineers. Almost every IT department seeks an analyst who can crunch information from the data to predict the future and make the company 
                aware of the policies that it needs to make. One of the greatest development in the field of Machine Learning is image recognition. Though there are several algorithms
                which focusses on playing of games and particular use of deep reinforcement learning, our experiment explores the concept of a rather simple model of automating games.
                The model that we have used is developed over the years by eminent researchers by trial and errors. We have tweaked some of the parameters and shown that just 
                by seeing and learning, the computer can perform a lot of tasks which can automate many things in day to day life.
                <br>
                <p>
                <center>
                <span id="yt_video_ppt_dino_cnn">
                    <iframe width="55%" height="315" src="https://www.youtube.com/embed/MBvTg_sID_U" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
                </span>
                <center>
                    <i>Video 1: Beamer presentation for Communicative English Course on this topic.</i> 
                </center>
                </center>
                </p>
                <br>

                <p>
                A CNN when applied in image recognition, acts on an image. That is, if we want to apply something using CNN into video, we have to extract the frames, and work on it. 
                The CNN might take about 0.4 second to do the job, then it is still a very bad algorithm, since there are 60 frames in one second and to act on real time systems, it shall
                be able to do atleast 30 operations per second. Though scientists are working consistently on this matter of improving the efficiency of algorithms which can be embedded 
                and shall be working on very low powered devices <a href="#jimut_mobilenet_paper"><u>[1]</u></a>.
                </p>
                <br>
                <br>

                <h3> Our Approach </h3>
                <br>
                Here, we will design and talk about those games (a certain class of games which are extremely simple to play) which will can be played automatically, and will see what is the exact 
                power of CNN in solving and automating tasks. There are rather very advanced models like the one which plays Go (alpha go), and others which uses advanced concepts of machine learning.
                The question was <span id="bold_id"><i>"Can CNN play pong game?"</i></span>. Firstly we have designed and used <a href="https://pythonprogramming.net/pong-ai-tensorflowjs-tutorial/" alt="sentdex codes" target="blank">pong game,</a> designed by Harrison and 
                applied it to our <a href="../games/pong_classic/index.html" alt="pong game local" target="_blank">version</a>. The answer lies by asking ourself another question, i.e., can we predict the next move of the player when we are playing one to one 
                with computer by <span id="bold_id"><i>just looking at a static image?</i></span> as shown in <a href="#questionAI"><i> Fig. 1 </i></a>.

                <br/>
                <br/>
                <center>
                    <img src="blog_img/cnn_ai/pong_ques.png" id = "questionAI" alt="question AI" height="70%" width="70%">
                </center>
                <center>
                    <i>Fig. 1: Which direction (up or down?) shall the right paddle move?</i> 
                </center>
                <br>

                The answer is NO, we can't predict the move of the Pong by just looking at the image. But, if we are given that the ball is moving towards the player (right paddle), then we may
                assume that the player might want to go down (just think of an invisible ray coming from the ball and hitting the wall), else, if the ball goes to the direction of the 
                computer, then the player has the tendency to go upward direction (or may be stationary, though it completely depends on how the player is going to act then ). Due to the fact that 
                we are unaware of the direction of the ball, we may sometime move the paddle "Up" or sometime move the paddle "Down". We might even ignore the cases when the ball is moving away from 
                the player to the computer, since it may be a waste of computation (the AI needs to act only when the ball is coming towards itself). This thing can be sucessfully modelled by using 
                reinforcement learning or some variations of LSTM (Long short term memory model). Our aim is to explore only those subsets of game which are easily and sucessfully played by CNN.

                Nevertheless, we have made it play, which almost saves the ball from hitting the wall many times, but it doesn't (or rarely) makes score against the Robot computer (since we have tested 
                it with simple CNN model). The video of the performance of the AI is shown in <a href="#yt_video_pong_cnn">Video 1</a>. The poor performance of the AI is due to the fact that for making the 
                moves, we need to consider other pictures too (i.e., at least some previous pictures). 
                <br>
                <br>
                &nbsp
                <center>
                <span id="yt_video_pong_cnn">
                    <iframe width="55%" height="315" src="https://www.youtube.com/embed/fstrysR7ZBA" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
                </span>
                </center>
                <center>
                    <i>Video 2: CNN trained pong AI rarely saves the ball from hitting the right wall</i> 
                </center>
                <br>
                <br>

                <h3> Tutorial </h3>
                <br>
                Let's see how we have done this using Python 3. Firstly we need to build a system which can collect the data for the training of the AI. For a CNN to get trained, we need labelled data. For this, we have written a 
                <a href="#script1_collect_data">script</a>. The purpose of this script is it takes the action as one hot encoded value (i.e.,a map of  number corresponding to the actions), and stores the actions in a 
                CSV (comma separated value) file. The line number corresponds to the frame of the images, and we collect the corresponding image and store it in a different folder. The images obtained are shown in <a href="#2k_images">Fig. 2</a>. 
                Unlike Harrison, we have used the <span id="bold_id">"human touch"</span>, by not training it with Robot Pong AI (which calculates the move with the help of certain mathematical constraint and then acts accordingly).
                The human touch can help the AI do incredeble things, like increasing the speed of the paddle by consistently pressing one button, but in the case of the AI which is trained using the Robot, it would look like the AI is acting optimally
                everytime by using mathematical constraint, which means it can't do the <span id="bold_id">miracle</span>. In other words, the AI can't take decisions like speeding up when the ball is coming at a high pace towards the paddle, and will be 
                unable to save the ball. By looking at the video we cannot determine whether it is the AI or the human that is playing, since the AI learns from human and this makes any machine learning AI to perform tasks that the human can perform exactly the 
                same way.

                &nbsp
                <br>
                &nbsp
                <br>
                <span id="script1_collect_data">
                    <script src="https://gist.github.com/Jimut123/f3b2e6f42ccfa02c6245b645770cc1a3.js"></script>
                </span>

                <center>
                    <i>Script 1: A script in Python3 to create the data for training.</i> 
                </center>
                &nbsp
                <br>

                <center>
                    <img src="blog_img/cnn_ai/cnn_ai_images.png" id = "2k_images" alt="images" height="70%" width="70%">
                </center>
                <center>
                    <i>Fig. 2: The images collected for training.</i> 
                </center>
                &nbsp
                <br>

                After the data collection, we need to train it. The Python3 <a href="#script2_training">script</a> for training is shown. This is the Cifar-10 model, which has created a benchmark around the year 2015.

                &nbsp
                <br>
                &nbsp
                <br>
                <span id="script2_training">
                    <script src="https://gist.github.com/Jimut123/f54b792f5c4e3ad242c545984d82f888.js"></script>
                    
                </span>
                <center>
                    <i>Script 2: A script in Python3 to train the data.</i> 
                </center>
                &nbsp
                <br>
                &nbsp
                <br>
                We have trained it on Colab (google collaboratory) using the GPU runtime, by uploading the data in a zip file, unziping it there and downloading the trained .h5py model and testing it on our local machine.
                The most awesome thing about google <a href="https://colab.research.google.com/notebooks/gpu.ipynb#scrollTo=eG8w0N9zjRhM" target="_blank">collaboratory</a> is that it is free, and uses <a href="https://cloud.google.com/blog/products/ai-machine-learning/nvidia-tesla-t4-gpus-now-available-in-beta" target="_blank" alt="T4">NVIDIA Tesla T4 GPUs</a>.
                After downloading the .h5py file, which was trained in a few minutes, we used this <a href="script3_run_ai"> script</a> to let the <a href="#yt_video_pong_cnn">pong AI </a>run in our local machine. 
                &nbsp
                <br>
                &nbsp
                <br>
                <span id="script3_run_ai">
                    <script src="https://gist.github.com/Jimut123/6fcc90002d82f14f0dfa679f1c8e2f58.js"></script>
                </span>

                <center>
                    <i>Script 3: A script in Python3 to run the AI on local machine.</i> 
                </center>
                &nbsp
                <br>
                
                <br>

                <h3>Conclusions </h3>
                <br>
                
                When training the AI for 2k images, we get the result as shown in <a href="#err_Acc_2k_img">Fig. 3</a>. This result is pretty amazing, and gives over 85% accuracy on train and test set.
                Since this is only 2000 images, (for up action = 1K images and for down action= another 1K image) this doesn't fall in the domain of big data. When we are using 30K images, which very minutely falls in the domain of big data (very very minutely), we see how the model is actually
                affecting the train and test images as shown in <a href="#30k_images"> Fig. 4</a>.
                <center>
                    <img src="blog_img/cnn_ai/cnn_2k.png" id = "err_Acc_2k_img" alt="images" height="70%" width="70%">
                </center>
                <center>
                    <i>Fig. 3: The results obtained by training 2k images.</i> 
                </center>
                &nbsp
                <br>
                <br>

                <center>
                    <img src="blog_img/cnn_ai/cnn_30k.png" id = "30k_images" alt="images" height="70%" width="70%">
                </center>
                <center>
                    <i>Fig. 4: The results obtained by training 30k images.</i> 
                </center>
                &nbsp
                <br>
                &nbsp
                <br>
                This shows that the game cannot perform good when we are training it with more data. The accuracy of about 56% on the train and 50% on the test data shows that it will not perform well, we need to use a different model. 
                When the data is more, the model have to perform well, if it is not performing well, (when not giving at least 90% accuracy) we need to change our model (without thinking anything else).
                &nbsp
                <br>
                &nbsp
                <br>
                <h3>Your task</h3>
                &nbsp
                <br>
                We have seen that this model doesn't perform well in the case of Pong AI, but we haven't tried for Dino game as shown in <a href="#google_dino">Fig. 5 </a>(which is inbuilt in google chrome browser). 
                Your task (should you choose to accept it), shall be to implement this set up for dino game. From intuition we can almost tell the next move by looking at the picture of the dino game, but it may happen that the speed increases over 
                time so, the CNN AI is not able to determine the time for jump when it has not looked the future. For that I have build this <a href="../games/JumpAndRoll2D/index.html" alt="jump and roll" target="_blank">game </a>named as jump and roll 2D.
                This is a dino clone, but with constant speed. The CNN shall give over 90% accuracy for this game, and shall be able to perform satisfactory. The only problem with this game is it is very hard to collect the data for such a booring game like this.
                But nonetheless, you can use the classic Dino game inbuilt in chrome to make the AI work for only "day time". 
                &nbsp
                <br>
                
                

                <center>
                    <img src="blog_img/cnn_ai/google_dino.png" id = "google_dino" alt="images" height="70%" width="70%">
                </center>
                <center>
                    <i>Fig. 5: The famous Dino Game, look ma, no internet!</i> 
                </center>
                &nbsp
                <br>
                &nbsp
                <br>

                It is bound to give satisfactory result.  When done  <a href="mailto:jimutbahanpal@yahoo.com" >mail me your result!</a>
                Till then, happy learning!
                
                &nbsp
                <br>
                <br>

                <h3>#Update: </h3>
                <p>

                After working with the data that I collected by playing a hacked version (minimal) of the Google's Dino Game, I got some satisfactory results. The result wasn't perfect because
                of the lag in my PC to collect the data of the screenshot at the moment when I pressed the "Jumping action" (spacebar or uparrow). But, nonetheless, lets see the video of the dino game 
                in <a href="#yt_video_dino_cnn"> action:</a>

                </p>
                <p>
                <center>
                <span id="yt_video_dino_cnn">
                    <iframe width="55%" height="315" src="https://www.youtube.com/embed/nQw8KtcOynA" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
                </span>
                <center>
                    <i>Video 3: CNN trained dino AI satisfactorily saves itself from hitting and colliding</i> 
                </center>
                </center>
                </p>

                Even from stats perspective we can see the <a href="#acc_dino"> accuracy </a> and <a href="#err_dino"> error</a> in the following figures.

                <center>
                    <img src="blog_img/cnn_ai/accuracy_dino_1.png" id = "acc_dino" alt="images" height="70%" width="70%">
                </center>

                <center>
                    <i>Fig. 6: The accuracy of Dino AI obtained by training 2k images.</i> 
                </center>
                <center>
                    <img src="blog_img/cnn_ai/loss_dino_2.png" id = "err_dino" alt="images" height="70%" width="70%">
                </center>
                <center>
                    <i>Fig. 7: The error of Dino AI obtained by training 2k images.</i> 
                </center>
                <br><br>
                Finally our implementation of the model is shown in <a href="#model_our">Fig. 8</a>.
                <br><br>
                <center>
                    <img src="blog_img/cnn_ai/our_implementation.png" id = "model_our" alt="images" height="50%" width="50%">
                </center>
                <center>
                    <i>Fig. 8: Our implementation of the CIFAR-10 model.</i> 
                </center>


                <br>
                <br>
                <h3>References</h3>
                <br>
                1. <span id="jimut_mobilenet_paper">  Jimut Bahan Pal, Shalabh Agarwal, “Real Time Object Detection Can be Embedded on Low Powered Devices”, International Journal of Computer Sciences and Engineering, Vol.7, Issue.2, pp.1005-1009, 2019. </span>
                &nbsp
                <br>
                2. <a href="../blogs/cnn_games_ai_ipynb.html" alt="ipynb file" target="_blank"> The Jupyter Notebook for Colab. </a>
            </div>
    </div>
</div>


      <br><br>
      
    </div>

  


  <!-- Footer -->
  <footer class="footer page-footer font-small pt-1">
    <div  align="center">
      
          <!-- Copyright -->
          <div class="footer-copyright" style="color: rgb(217, 61, 61);"> 2019-2025
              <a href="https://github.com/Jimut123" style="color: rgb(217, 61, 61);"> Copyright © Jimut Bahan Pal</a>
          </div>
          <!-- Copyright -->
    </div>
  </footer>
  <!-- Footer -->



</body>
</html>
<style>
.footer{
  position: fixed;
  bottom: 0;
  width: 100%;

}
</style>


<script>
  var preloader = document.getElementById('loading');
  function myFunction() { 
      preloader.style.display = 'none';
  }
</script>