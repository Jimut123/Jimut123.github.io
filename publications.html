<!doctype html>


<link href="https://fonts.googleapis.com/css?family=Cardo&display=swap" rel="stylesheet"> 

<link rel="stylesheet" href="../css/bootstrap.min.css"></link>
<!--
<link rel="stylesheet" href="/css/compiled-4.8.0.min.css"></link>
-->
<script type="text/javascript"  src="../js/bootstrap.min.js"></script>

<script type="text/javascript"  src="../js/jquery-3.2.1.slim.min.js"></script>
<script type="text/javascript"  src="../js/popper.min.js"></script>


<link rel='stylesheet' id='wsl-widget-css'  href='https://mdbootstrap.com/wp-content/plugins/wordpress-social-login/assets/css/style.css?ver=5.1.1' type='text/css' media='all' />

<link rel='stylesheet' id='compiled.css-css'  href='https://mdbootstrap.com/wp-content/themes/mdbootstrap4/css/compiled-4.8.0.min.css?ver=4.8.0' type='text/css' media='all' />


<link rel="shortcut icon" type="image/x-icon" href="../img/thumbnail.jpg">


<!-- Bootstrap core CSS -->

<link href="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/4.3.1/css/bootstrap.min.css" rel="stylesheet">

<!-- Material Design Bootstrap -->

<link href="https://cdnjs.cloudflare.com/ajax/libs/mdbootstrap/4.8.0/css/mdb.min.css" rel="stylesheet">



<!-- Bootstrap core JavaScript -->

<script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/4.3.1/js/bootstrap.min.js"></script>


<!-- Lazy loading of Gallery and stuffs!-->

<script src="../js/jimjs.js"></script>
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/normalize/7.0.0/normalize.min.css">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.2/css/all.css" integrity="sha256-46qynGAkLSFpVbEBog43gvNhfrOj+BmwXdxFgVK/Kvc=" crossorigin="anonymous" /> 



<html>
  <head>
    <meta charset="utf-8">
    
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="author" content="Jimut Bahan Pal" />
    <meta name="description" content="Personal website">
    <meta name="google-site-verification" content="2SC5t4-rLXOS1eAW-l2YL_qFLuIJW2vSRZNduyOGKN0" />
    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-140291358-1"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'UA-140291358-1');
    </script>

    
    <title> Publications </title>
  </head>

  <body onload = "myFunction()">
    <div id="loading"> </div>
    
    
<!------ Include the above in your HEAD tag ---------->

<nav class="navbar navbar-icon-top navbar-expand-lg navbar-dark bg-dark sticky-top">
  <a class="navbar-brand" href="#"> JIMUT </a>

  <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarSupportedContent" 
  aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">

  <span class="navbar-toggler-icon"></span>
  </button>

  <div class="collapse navbar-collapse" id="navbarSupportedContent">
    
    <ul class="navbar-nav mr-auto navbar-center">
      
              <li class="nav-item">
                <div class="container pull-left">
                  <a href="/"  class="nav-link">
                    
                      
                        <img src="/img/icons/home.svg" alt="icon" height="25px" width="25px">
                      
                   
                    <font size="4px">HOME </font>
                  </a>
                </div>
              </li>
          
              <li class="nav-item">
                <div class="container pull-left">
                  <a href="/publications.html"  style="color: #f9d210;" class="nav-link">
                    
                      
                        <img src="/img/icons/publications.png" alt="icon" height="25px" width="25px">
                      
                   
                    <font size="4px">PUBLICATIONS </font>
                  </a>
                </div>
              </li>
          
              <li class="nav-item">
                <div class="container pull-left">
                  <a href="/blog.html"  class="nav-link">
                    
                      
                        <img src="/img/icons/blog.svg" alt="icon" height="25px" width="25px">
                      
                   
                    <font size="4px">BLOG </font>
                  </a>
                </div>
              </li>
          
              <li class="nav-item">
                <div class="container pull-left">
                  <a href="/projects.html"  class="nav-link">
                    
                      
                        <img src="/img/icons/projects.jpg" alt="icon" height="25px" width="25px">
                      
                   
                    <font size="4px">PROJECTS </font>
                  </a>
                </div>
              </li>
          
              <li class="nav-item">
                <div class="container pull-left">
                  <a href="/gallery.html"  class="nav-link">
                    
                      
                        <img src="/img/icons/gallery.png" alt="icon" height="25px" width="25px">
                      
                   
                    <font size="4px">GALLERY </font>
                  </a>
                </div>
              </li>
          
              <li class="nav-item">
                <div class="container pull-left">
                  <a href="/personal.html"  class="nav-link">
                    
                      
                        <img src="/img/icons/certificates.png" alt="icon" height="25px" width="25px">
                      
                   
                    <font size="4px">PERSONAL </font>
                  </a>
                </div>
              </li>
          
    </ul>
  
  </div>
</nav>


<script type="text/javascript">
  $(function() {
      // this will get the full URL at the address bar
      var url = window.location.href;

      // passes on every "a" tag
      $(".navbar a").each(function() {
          // checks if its the same on the address bar
          if (url == (this.href)) {
              $(this).closest("li").addClass("active");
              //for making parent of submenu active
             $(this).closest("li").parent().parent().addClass("active");
          }
      });
  });        
</script>


<style>

.navbar ul li.active a, .navbar ul li a:hover {
    background-color: #454747;
    font-weight:bold;
}
</style>



    <div align="center">
    
   
    
      
      <link href="https://fonts.googleapis.com/css?family=Playfair+Display&amp;display=swap" rel="stylesheet" />

<html>
    <h1>
        <b style="font-family: 'Playfair Display', serif;">  PUBLICATIONS</b>
    </h1>
</html>

<!--
    <b><i class="fas fa-chevron-circle-right"></i> <a id = "sucess-link"href="http://ijarcsms.com/docs/paper/volume6/issue10/V6I10-0031.pdf" target="_blank">Botnets: A constant threat to cyberspace </a>. <a id = "sucess-link" onclick="window.open('https://drive.google.com/open?id=196CA1C81ZOd-BzCTQ67anwI_n3ZF1Mnp');
          window.open('https://drive.google.com/open?id=1FWGG9MaOXC169E9g6qwvjTfb4_kRMNgn');" target="_blank">IJARCSMS</a>. Nov 12, 2018. </b>
        <br>
-->
<link href="https://fonts.googleapis.com/css?family=Cardo&amp;display=swap" rel="stylesheet" />

<p><br /></p>
<div itemscope="" itemtype="https://schema.org/Person"><a itemprop="sameAs" content="https://orcid.org/0000-0002-1206-7902" href="https://orcid.org/0000-0002-1206-7902" target="orcid.widget" rel="noopener noreferrer" style="vertical-align:top;"><img src="https://orcid.org/sites/default/files/images/orcid_16x16.png" style="width:1em;margin-right:.5em;" alt="ORCID iD icon" />https://orcid.org/0000-0002-1206-7902</a></div>
<p><br /></p>

<link rel="stylesheet" type="text/css" href="../css/jimstyle.css" />

<p><!-- Bootstrap Bundle with Popper -->
 <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.0.1/dist/js/bootstrap.bundle.min.js" integrity="sha384-gtEjrD/SeCtmISkJkNUaaKMoLD0//ElJ19smozuHV6z3Iehds+3Ulb9Bn9Plx0x4" crossorigin="anonymous"></script></p>

<style>
    .btn:hover
    {
    background-image:none !important;
    background-color:#f9d210 !important;
    }
</style>

<div id="pad-container">
    <div class="jumbotron jumbotron-fluid" align="justify">
        <div class="container" id="publication-font">
            

                



                    <div class="row g-0">
                        <div class="col-md-4 text-center my-4 px-2">
                            <img src="../publications/RV_PBS/rv_pbs.jpg" width="100%" style="box-shadow: 4px 4px 8px #888" class="center" />
                        </div>
                        <div class="col-md-8 my-4">
                            <div class="card-body">
                                <h5 class="card-title">
                                    <strong>Instance Segmentation of Peripheral Blood Smear and Refining Classification via Domain Adaptation</strong>
                                </h5>
                                <a id="bold_id"> Jimut Bahan Pal</a>, <strong><a href="https://abhattacharyea.dev/" target="_blank"> Aniket Bhattacharyea</a></strong>, <strong><a href="http://narendrapur.rkmvu.ac.in/wp-content/uploads/2020/09/Dr.-Debasis-Bandyopadhyay-Banerjee-CV.pdf" target="_blank"> Debasis Banerjee</a></strong> and <strong><a href="https://cse.buffalo.edu/~tamaltan/welcome/welcome.html" target="_blank" alt="Tamal's Buffalo Website"> Tamal </a> <a href="http://cs.rkmvu.ac.in/~tamal/" target="_blank" alt="Tamal's RKMVERI Website"> Maharaj </a> </strong>
                                <br />
                                Under Review
                                <br />
                                <p>
                                    
                                        <a class="btn btn-outline-dark" data-bs-toggle="collapse" href="#abstractrv_pbs" role="button" aria-expanded="false" aria-controls="abstractrv_pbs">Abstract</a>
                                    

                                    

                                    

                                    

                                    

                                    
                                   
                                </p>
                                
                                
                                    <div class="collapse" id="abstractrv_pbs">
                                        <div class="card card-body" align="justify">
                                            Automating counting and detection of different blood cells from a smear slide can help doctors to diagnose diseases via blood test. In the current literature, whole slide data has not yet been considered. This study deals with creation of a novel 10 class peripheral blood smear dataset, the RV-PBS dataset. Standard architectures such as Mask R-CNN shows promising results in segmenting instances of blood cells, hence creating scope for semi-supervised annotation of newer data samples. Fewer data samples and data imbalance in the dataset helps us to employ innovative techniques such as domain adaptation using a similar dataset for improving the classification accuracy of the Mask R-CNN. In this study, we have successfully created a pipeline which will segment, detect and classify blood samples from slides. This in turn can count and get an estimate of the type of blood cell present to help the doctors refine their analysis.
                                        </div>
                                    </div>
                                

                                
                                
                            </div>
                        </div>
                    </div>


                



                    <div class="row g-0">
                        <div class="col-md-4 text-center my-4 px-2">
                            <img src="../publications/BMSAN/bmsan.jpg" width="100%" style="box-shadow: 4px 4px 8px #888" class="center" />
                        </div>
                        <div class="col-md-8 my-4">
                            <div class="card-body">
                                <h5 class="card-title">
                                    <strong>Improving Multi Scale Attention Networks - Bayesian Optimization for Segmenting medical images</strong>
                                </h5>
                                <a id="bold_id"> Jimut Bahan Pal </a> and <strong><a href="https://web.archive.org/web/20200624004219/http://www2.eng.ox.ac.uk/civil/efm/people/dripta-sarkar" target="_blank"> Dripta Mj </a></strong>
                                <br />
                                Under Review
                                <br />
                                <p>
                                    
                                        <a class="btn btn-outline-dark" data-bs-toggle="collapse" href="#abstractbmsan" role="button" aria-expanded="false" aria-controls="abstractbmsan">Abstract</a>
                                    

                                    

                                    

                                    

                                    

                                    
                                   
                                </p>
                                
                                
                                    <div class="collapse" id="abstractbmsan">
                                        <div class="card card-body" align="justify">
                                            Medical sectors are facing challenges to segment images with high accuracy. Earlier methods were limited to segmenting few datasets with a large number of parameters. In this study a novel Deep Learning architecture is proposed that can segment images at multiple scales, leading to high dice coefficient in majority of challenging datasets, where regions of interest are of different shapes and sizes. Using attention module within the architecture partly increases the capability of the model to focus on relevant regions. Calculating loss at different scales also aids in incremental reconstruction of segmentation mask. To further improve the segmentation results Bayesian Optimization is carried out by selecting the weighted combination of losses at different scales. A comparison with other state of the art model shows this model performs better than most of the models with a significantly low computation overhead. This demonstrates the efficiency and reliability of this approach to generate segmentation masks for medical images.
                                        </div>
                                    </div>
                                

                                
                                
                            </div>
                        </div>
                    </div>


                



                    <div class="row g-0">
                        <div class="col-md-4 text-center my-4 px-2">
                            <img src="../publications/MICCAI_QUBIQ_21/qubiq_21.jpg" width="100%" style="box-shadow: 4px 4px 8px #888" class="center" />
                        </div>
                        <div class="col-md-8 my-4">
                            <div class="card-body">
                                <h5 class="card-title">
                                    <strong>Holistic network for quantifying uncertainties in medical images</strong>
                                </h5>
                                <a id="bold_id"> Jimut Bahan Pal </a>
                                <br />
                                Accepted at BrainLes 2021 MICCAI Workshop, to be published in Springer LNCS
                                <br />
                                <p>
                                    
                                        <a class="btn btn-outline-dark" data-bs-toggle="collapse" href="#abstractmiccai_qubiq_21" role="button" aria-expanded="false" aria-controls="abstractmiccai_qubiq_21">Abstract</a>
                                    

                                    

                                    
                                        <a class="btn btn-outline-dark" href="../publications/MICCAI_QUBIQ_21/Jimut_Bahan_Pal_QUBIQ_MICCAI.pdf" target="_blank">Slide</a>
                                    

                                    
                                        <a class="btn btn-outline-dark" href="https://www.youtube.com/watch?v=AaVvNG-ihMU" target="_blank">Video</a>
                                    

                                    
                                        <a class="btn btn-outline-dark" href="https://github.com/Jimut123/MICCAI_QUBIQ_21" target="_blank">Code</a>
                                    

                                    
                                   
                                </p>
                                
                                
                                    <div class="collapse" id="abstractmiccai_qubiq_21">
                                        <div class="card card-body" align="justify">
                                            Variability in delineation is an inherent property for segmenting medical imagery, when images are annotated by a variety of expert annotators. Previous methods have used adversarial training, Monte-Carlo sampling, and dropouts, which might sometimes produce a wide range of segmentation masks that differ from the styles of mask produced by a set of expert annotators. State-of-the-art method uses multiple U-Nets to capture the individual delineations, but it is computationally demanding. To mitigate this problem, a holistic network containing N-Encoder and N-Decoder is proposed, which could individually model the variability of delineation produced by the expert annotators. This will help to create segmentation masks for different tasks of the same dataset through a single network by learning the common features of multiple Encoders via a common channel and passing those features to Decoder. These create one segmentation mask. All the masks are calculated by using weighted loss at each end of the Decoders that show excellent results for some datasets.
                                        </div>
                                    </div>
                                

                                
                                
                            </div>
                        </div>
                    </div>


                



                    <div class="row g-0">
                        <div class="col-md-4 text-center my-4 px-2">
                            <img src="../publications/CXR_19/cxr_19.jpg" width="100%" style="box-shadow: 4px 4px 8px #888" class="center" />
                        </div>
                        <div class="col-md-8 my-4">
                            <div class="card-body">
                                <h5 class="card-title">
                                    <strong>Classifying Chest X-Ray COVID-19 images via Transfer Learning</strong>
                                </h5>
                                <a id="bold_id"> Jimut Bahan Pal </a> and <strong><a href="https://github.com/nlACh" target="_blank"> Nilayan Paul </a></strong>
                                <br />
                                2021 Ethics and Explainability for Responsible Data Science (EE-RDS), published in IEEE Xplore
                                <br />
                                <p>
                                    
                                        <a class="btn btn-outline-dark" data-bs-toggle="collapse" href="#abstractcxr_19" role="button" aria-expanded="false" aria-controls="abstractcxr_19">Abstract</a>
                                    

                                    
                                        <a class="btn btn-outline-dark" href="https://ieeexplore.ieee.org/document/9708580" target="_blank">Article</a>
                                    

                                    
                                        <a class="btn btn-outline-dark" href="../publications/CXR_19/CXR_COVID_19_slide.pdf" target="_blank">Slide</a>
                                    

                                    
                                        <a class="btn btn-outline-dark" href="https://www.youtube.com/watch?v=27ixHn6SP_4" target="_blank">Video</a>
                                    

                                    
                                        <a class="btn btn-outline-dark" href="https://github.com/Jimut123/CXR_Covid-19" target="_blank">Code</a>
                                    

                                    
                                        <a class="btn btn-outline-dark" data-bs-toggle="collapse" href="#bibcxr_19" role="button" aria-expanded="false" aria-controls="bibcxr_19">Bibtex</a>
                                    
                                   
                                </p>
                                
                                
                                    <div class="collapse" id="abstractcxr_19">
                                        <div class="card card-body" align="justify">
                                            The internal behavior of Deep Neural Network architectures can be difficult to interpret. Certain architectures achieve impressive feats in a particular dataset while failing to show comparable performance in other datasets. Developing an architecture that performs well on a dataset can be a time-consuming affair and computationally intensive process. This study explains the effect of transfer learning by fine-tuning already available state-of-the-art architectures in different datasets and using them to classify Chest X-Ray images with high accuracy. Using transfer learning helps the model learn problem-specific features in a short period. It further shows that different models perform differently in a particular setting for a dataset. Ablation studies show that a combination of smaller structures that gives an overall better result may not give the best result in the combined model. In addition, the “belief” of the model for selecting a particular class is visualized in this study.
                                        </div>
                                    </div>
                                

                                
                                    <div class="collapse" id="bibcxr_19">
                                        <div class="card card-body" align="justify">
                                            <object data="../publications/CXR_19/9708580.txt" width="100%"></object>
                                        </div>
                                    </div>
                                
                                
                            </div>
                        </div>
                    </div>


                

            
          


 </div>
</div>









</div>

      
    
    
  </div>

  


  <!-- Footer -->
  <footer class="footer page-footer font-small elegant-color-dark pt-1">
    <div  align="center">



          <!-- Copyright -->
          <div class="footer-copyright"> 2019-2022
              <a href="https://github.com/Jimut123"> Copyright © Jimut Bahan Pal</a>
          </div>
          <!-- Copyright -->
    </div>
  </footer>
  <!-- Footer -->



</body>
</html>
<style>
.footer{
  position: fixed;
  bottom: 0;
  width: 100%;

}
</style>


<script>
  var preloader = document.getElementById('loading');
  function myFunction() { 
      preloader.style.display = 'none';
  }
</script>