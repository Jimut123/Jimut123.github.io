<!doctype html>

<!-- DNS Preconnect for faster external resource loading -->
<link rel="preconnect" href="https://fonts.googleapis.com">
<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
<link rel="preconnect" href="https://cdnjs.cloudflare.com">
<link rel="preconnect" href="https://mdbootstrap.com">

<link href="https://fonts.googleapis.com/css?family=Cardo&display=swap" rel="stylesheet"> 

<link rel="stylesheet" href="../css/bootstrap.min.css"></link>
<!--
<link rel="stylesheet" href="/css/compiled-4.8.0.min.css"></link>
-->
<script type="text/javascript"  src="../js/bootstrap.min.js"></script>

<script type="text/javascript"  src="../js/jquery-3.2.1.slim.min.js"></script>
<script type="text/javascript"  src="../js/popper.min.js"></script>


<link rel='stylesheet' id='wsl-widget-css'  href='https://mdbootstrap.com/wp-content/plugins/wordpress-social-login/assets/css/style.css?ver=5.1.1' type='text/css' media='all' />

<link rel='stylesheet' id='compiled.css-css'  href='https://mdbootstrap.com/wp-content/themes/mdbootstrap4/css/compiled-4.8.0.min.css?ver=4.8.0' type='text/css' media='all' />


<link rel="shortcut icon" type="image/x-icon" href="../img/thumbnail.jpg">


<!-- Bootstrap core CSS -->

<link href="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/4.3.1/css/bootstrap.min.css" rel="stylesheet">

<!-- Material Design Bootstrap -->

<link href="https://cdnjs.cloudflare.com/ajax/libs/mdbootstrap/4.8.0/css/mdb.min.css" rel="stylesheet">



<!-- Bootstrap core JavaScript -->

<script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/4.3.1/js/bootstrap.min.js"></script>


<!-- Lazy loading of Gallery and stuffs!-->

<script src="../js/jimjs.js"></script>
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/normalize/7.0.0/normalize.min.css">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.2/css/all.css" integrity="sha256-46qynGAkLSFpVbEBog43gvNhfrOj+BmwXdxFgVK/Kvc=" crossorigin="anonymous" /> 

<link rel = "stylesheet" type = "text/css" href = "../css/jimstyle.css" />

<html>
  <head>
    <meta charset="utf-8">
    
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="author" content="Jimut Bahan Pal" />
    <meta name="description" content="Personal website of Jimut Bahan Pal - Researcher, Developer, and Machine Learning enthusiast. Explore projects, publications, blogs, and more.">
    <meta name="keywords" content="Jimut Bahan Pal, machine learning, deep learning, computer vision, IIT Bombay, research, projects, publications">
    <meta name="google-site-verification" content="2SC5t4-rLXOS1eAW-l2YL_qFLuIJW2vSRZNduyOGKN0" />
    
    <!-- Canonical URL -->
    <link rel="canonical" href="http://localhost:4000/publications.html">
    
    <!-- Open Graph Meta Tags for Social Sharing -->
    <meta property="og:title" content="Publications">
    <meta property="og:description" content="Personal website of Jimut Bahan Pal - Researcher, Developer, and Machine Learning enthusiast. Explore projects, publications, blogs, and more.">
    <meta property="og:type" content="website">
    <meta property="og:url" content="http://localhost:4000/publications.html">
    <meta property="og:image" content="http://localhost:4000/img/jimut.jpeg">
    <meta property="og:site_name" content="Jimut Bahan Pal - Personal Website">
    <meta property="og:locale" content="en_IN">
    
    <!-- Twitter Card Meta Tags -->
    <meta name="twitter:card" content="summary_large_image">
    <meta name="twitter:title" content="Publications">
    <meta name="twitter:description" content="Personal website of Jimut Bahan Pal - Researcher, Developer, and Machine Learning enthusiast. Explore projects, publications, blogs, and more.">
    <meta name="twitter:image" content="http://localhost:4000/img/jimut.jpeg">
    <meta name="twitter:creator" content="@jimutpal">
    
    <!-- Additional SEO Meta Tags -->
    <meta name="robots" content="index, follow">
    <meta name="googlebot" content="index, follow, max-image-preview:large">
    
    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-140291358-1"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'UA-140291358-1');
    </script>

    
    <title> Publications </title>
  </head>

  <body onload = "myFunction()">
    <div id="loading"> </div>
    
    <!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Theme Toggle Example</title>
    <link rel="stylesheet" type="text/css" href="../css/jimstyle.css" />

    <style>
        /* Define light theme */
        :root {
            --background-color: #ffffff;
            --text-color: #000000;
            --container-bg: #ffffff;
            --container-text: #000000;
            --special-color: #0076f4;
            --navbar-bg: rgba(255, 255, 255, 0);
            --navbar-backdrop: blur(2px);
            --toggler-glow-color: #18a236; /* Green glow color */
        }

        /* Define dark theme */
        [data-theme="dark"] {
            --background-color: #413f3f;
            --text-color: #ffffff;
            --container-bg: #413f3f;
            --container-text: #ffffff;
            --special-color: #bb86fc;
            --navbar-bg: rgba(65, 63, 63, 0.5);
            --navbar-backdrop: blur(2px);
            --toggler-glow-color: #18a236; /* Same green glow in dark mode */
        }

        /* Apply themes to the body and all elements */
        body {
            background-color: var(--background-color);
            color: var(--text-color);
            transition: background-color 0.5s, color 0.5s;
        }

        /* Updated navbar styling */
        .navbar {
            background-color: var(--navbar-bg) !important;
            backdrop-filter: var(--navbar-backdrop);
            -webkit-backdrop-filter: var(--navbar-backdrop);
            transition: all 0.5s ease;
            border-bottom: 1px solid rgba(255, 255, 255, 0.1);
        }

        /* Ensure navbar text is visible in both themes */
        .navbar .nav-link {
            color: var(--text-color) !important;
        }

        /* Updated active link styling */
        .navbar ul li.active a, 
        .navbar ul li a:hover {
            background-color: rgba(229, 232, 209, 0.3);
            font-weight: bold;
        }

        /* Container styling */
        body div {
            background-color: var(--container-bg);
            color: var(--container-text);
            transition: background-color 0.5s, color 0.5s;
        }

        /* Override specific colors for dark theme */
        [data-theme="dark"] .btn-primary,
        [data-theme="dark"] .bg-primary,
        [data-theme="dark"] .text-primary {
            background-color: var(--special-color) !important;
            color: var(--container-text) !important;
        }

        #theme-icon {
            font-size: 2em;
        }

        /* Make navbar container transparent */
        .navbar .container {
            background-color: transparent !important;
        }

        /* NAVBAR TOGGLER GLOW EFFECT */
        @keyframes glowing-toggler {
            0% { box-shadow: 0 0 5px var(--toggler-glow-color); }
            50% { box-shadow: 0 0 20px var(--toggler-glow-color), 0 0 30px var(--toggler-glow-color); }
            100% { box-shadow: 0 0 5px var(--toggler-glow-color); }
        }

        /* Apply animation only when toggler is visible (on smaller screens) */
        @media (max-width: 991.98px) {
            .navbar-toggler {
                animation: glowing-toggler 2s infinite;
                border-color: var(--toggler-glow-color) !important;
            }
            
            /* Style the toggler icon bars with the same green color */
            .navbar-toggler-icon {
                background-image: url("data:image/svg+xml,%3csvg xmlns='http://www.w3.org/2000/svg' width='30' height='30' viewBox='0 0 30 30'%3e%3cpath stroke='rgba(24, 162, 54, 1)' stroke-linecap='round' stroke-miterlimit='10' stroke-width='2' d='M4 7h22M4 15h22M4 23h22'/%3e%3c/svg%3e") !important;
            }
        }
    </style>
</head>
<body>

<nav class="navbar navbar-icon-top navbar-expand-lg navbar-light sticky-top">
    <a class="navbar-brand" style="font-family: Georgia, Times, Times New Roman, serif;">
        <button id="theme-toggle" class="btn btn-link p-0" style="color: inherit;">
            <span id="theme-icon">üåû</span>
        </button>
    </a>

    <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarSupportedContent" 
    aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
        <span class="navbar-toggler-icon"></span>
    </button>

    <div class="collapse navbar-collapse" id="navbarSupportedContent">
        <ul class="navbar-nav mr-auto navbar-center" style="font-family: Georgia, Times, Times New Roman, serif;">
            
                <li class="nav-item">
                    <div class="container pull-left">
                        <a href="/"  class="nav-link">
                            
                                <img src="/img/icons/home.svg" alt="icon" height="25px" width="25px">
                            
                            <span size="4px" style="color: #18a236;">HOME </span>
                        </a>
                    </div>
                </li>
            
                <li class="nav-item">
                    <div class="container pull-left">
                        <a href="/publications.html"  style="color: #05f270;" class="nav-link">
                            
                                <img src="/img/icons/publications.png" alt="icon" height="25px" width="25px">
                            
                            <span size="4px" style="color: #18a236;">PUBLICATIONS </span>
                        </a>
                    </div>
                </li>
            
                <li class="nav-item">
                    <div class="container pull-left">
                        <a href="/blog.html"  class="nav-link">
                            
                                <img src="/img/icons/blog.svg" alt="icon" height="25px" width="25px">
                            
                            <span size="4px" style="color: #18a236;">BLOG </span>
                        </a>
                    </div>
                </li>
            
                <li class="nav-item">
                    <div class="container pull-left">
                        <a href="/projects.html"  class="nav-link">
                            
                                <img src="/img/icons/projects.jpg" alt="icon" height="25px" width="25px">
                            
                            <span size="4px" style="color: #18a236;">PROJECTS </span>
                        </a>
                    </div>
                </li>
            
                <li class="nav-item">
                    <div class="container pull-left">
                        <a href="/gallery.html"  class="nav-link">
                            
                                <img src="/img/icons/gallery.png" alt="icon" height="25px" width="25px">
                            
                            <span size="4px" style="color: #18a236;">GALLERY </span>
                        </a>
                    </div>
                </li>
            
                <li class="nav-item">
                    <div class="container pull-left">
                        <a href="/random.html"  class="nav-link">
                            
                                <img src="/img/icons/certificates.png" alt="icon" height="25px" width="25px">
                            
                            <span size="4px" style="color: #18a236;">RANDOM </span>
                        </a>
                    </div>
                </li>
            
                <li class="nav-item">
                    <div class="container pull-left">
                        <a href="/search/"  class="nav-link">
                            
                                <img src="/img/icons/search.png" alt="icon" height="25px" width="25px">
                            
                            <span size="4px" style="color: #18a236;">SEARCH </span>
                        </a>
                    </div>
                </li>
            
        </ul>
    </div>
</nav>

<script>
    const toggleButton = document.getElementById('theme-toggle');
    const themeIcon = document.getElementById('theme-icon');
    const body = document.body;

    const currentTheme = localStorage.getItem('theme');
    if (currentTheme) {
        body.setAttribute('data-theme', currentTheme);
        themeIcon.textContent = currentTheme === 'dark' ? 'üåú' : 'üåû';
    } else {
        body.setAttribute('data-theme', 'light');
        themeIcon.textContent = 'üåû';
    }

    toggleButton.addEventListener('click', () => {
        const currentTheme = body.getAttribute('data-theme');
        const newTheme = currentTheme === 'light' ? 'dark' : 'light';
        body.setAttribute('data-theme', newTheme);
        localStorage.setItem('theme', newTheme);
        themeIcon.textContent = newTheme === 'dark' ? 'üåú' : 'üåû';
    });
</script>

<script type="text/javascript">
    $(function() {
        var url = window.location.href;
        $(".navbar a").each(function() {
            if (url == (this.href)) {
                $(this).closest("li").addClass("active");
                $(this).closest("li").parent().parent().addClass("active");
            }
        });
    });        
</script>

</body>
</html>

    <div align="center">  
      <br><br>
      
      <link href="https://fonts.googleapis.com/css?family=Playfair+Display&amp;display=swap" rel="stylesheet" />

<html>
    <h1>
        <b id="heading-font">  PUBLICATIONS</b>
    </h1>
</html>

<!--
    <b><i class="fas fa-chevron-circle-right"></i> <a id = "sucess-link"href="http://ijarcsms.com/docs/paper/volume6/issue10/V6I10-0031.pdf" target="_blank">Botnets: A constant threat to cyberspace </a>. <a id = "sucess-link" onclick="window.open('https://drive.google.com/open?id=196CA1C81ZOd-BzCTQ67anwI_n3ZF1Mnp');
          window.open('https://drive.google.com/open?id=1FWGG9MaOXC169E9g6qwvjTfb4_kRMNgn');" target="_blank">IJARCSMS</a>. Nov 12, 2018. </b>
        <br>
-->
<link href="https://fonts.googleapis.com/css?family=Cardo&amp;display=swap" rel="stylesheet" />

<p><span id="front-page-font">Please refer to the <a href="https://scholar.google.com/citations?user=uyS3AKkAAAAJ&amp;hl=en" target="_blank">Google Scholar</a> page for updated list of publications.</span></p>

<p><br /></p>
<div itemscope="" itemtype="https://schema.org/Person"><a id="front-page-font" itemprop="sameAs" content="https://orcid.org/0000-0002-1206-7902" href="https://orcid.org/0000-0002-1206-7902" target="orcid.widget" rel="noopener noreferrer" style="vertical-align:top;"><img src="https://orcid.org/sites/default/files/images/orcid_16x16.png" style="width:1em;margin-right:.5em;" alt="ORCID iD icon" />ORCID ID: 0000-0002-1206-7902</a></div>
<p><br /></p>

<p><!-- Bootstrap Bundle with Popper -->
 <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.0.1/dist/js/bootstrap.bundle.min.js" integrity="sha384-gtEjrD/SeCtmISkJkNUaaKMoLD0//ElJ19smozuHV6z3Iehds+3Ulb9Bn9Plx0x4" crossorigin="anonymous"></script></p>

<style>
    .btn:hover
    {
    background-image:none !important;
    background-color:#90e0ef !important;
    }
</style>

<link rel="stylesheet" type="text/css" href="../css/jimstyle.css" />

<div id="pad-container">
    <div align="justify">
        <div class="container" id="publication-font">
            

                



                    <div class="row g-0">
                        <div class="col-md-4 text-center my-4 px-2">
                            <img src="../publications/WACV_24/wacv_24.png" width="100%" style="box-shadow: 4px 4px 8px #888" class="center" />
                        </div>
                        <div class="col-md-8 my-4">
                            <div class="card-body">
                                <h5 class="card-title">
                                    <span id="bold_id">Reviving Poor Object Segmentations in OOD Medical Images using Variational-Deep-PCA Modeling on Segmentation Maps with Sampling-Free Learning</span>
                                </h5>
                                <span id="bold_id"> Jimut Bahan Pal</span>, Shantanu Welling, Himali Saini and <a href="https://www.cse.iitb.ac.in/~suyash/index.html"> Suyash P. Awate </a>
                                <br />
                                Winter Conference on Applications of Computer Vision (WACV) 2024
                                <br />
                                <p>

                                    

                                    
                                        <a class="btn btn-sm" data-bs-toggle="collapse" href="#abstractshape_prior_wacv" role="button" aria-expanded="false" aria-controls="abstractshape_prior_wacv" id="pub-page-btn-font">Abstract</a>
                                    

                                    
                                        <a type="button" class="btn btn-sm" href="../publications/WACV_24/shape_prior_wacv_24.pdf" target="_blank" id="pub-page-btn-font">Article</a>
                                    

                                    

                                    

                                    

                                    

                                   
                                    
                                        <a class="btn btn-sm" data-bs-toggle="collapse" href="#bibshape_prior_wacv" role="button" aria-expanded="false" aria-controls="bibshape_prior_wacv" id="pub-page-btn-font">Bibtex</a>
                                    
                                   
                                </p>
                                
                                
                                    <div class="collapse" id="abstractshape_prior_wacv">
                                        <div class="card card-body" align="justify" style="color:  rgb(0, 136, 255); ">
                                            For object segmentation in medical images deep neural networks (DNNs) typically perform poorly on out-of-distribution (OOD) images stemming from the large variability in image-acquisition equipment and protocols across sites. However compared to such variability in the acquired medical images we observe that the variability in the underlying object-segmentation maps is far lower. Thus we propose a novel DNN framework to model this variability in segmentation maps and leverage it to revive poor segmentations produced by existing DNNs on OOD images. Our DNN framework (i) learns the principal modes of variation in a class of segmentation maps (ii) models each segmentation map using a low-dimensional mixture-of-modes latent representation on a simplex (iii) enables sampling-free variational learning and uncertainty estimation and (iv) trains using small in-distribution image sets. When OOD-image segmentations are extremely poor we propose a novel human-in-the-loop method needing minuscule human intervention. Results using 6 publicly-available datasets and 8 existing DNN segmenters show the benefits of our framework in OOD-image object segmentation.
                                        </div>
                                    </div>
                                

                                
                                    <div class="collapse" id="bibshape_prior_wacv">
                                        <div class="card card-body" align="justify" style="color:  rgb(0, 136, 255); ">
                                            <object data="../publications/WACV_24/shape_prior_wacv_24.txt" width="100%"></object>
                                        </div>
                                    </div>
                                

                                
                                
                            </div>
                        </div>
                    </div>


                



                    <div class="row g-0">
                        <div class="col-md-4 text-center my-4 px-2">
                            <img src="../publications/MICCAI_24/Arch_Conv_Seg_Final_MICCAI.png" width="100%" style="box-shadow: 4px 4px 8px #888" class="center" />
                        </div>
                        <div class="col-md-8 my-4">
                            <div class="card-body">
                                <h5 class="card-title">
                                    <span id="bold_id">Convex Segments for Convex Objects using DNN Boundary Tracing and Graduated Optimization</span>
                                </h5>
                                <span id="bold_id"> Jimut Bahan Pal</span> and <a href="https://www.cse.iitb.ac.in/~suyash/index.html"> Suyash P. Awate </a>
                                <br />
                                International Conference on Medical Image Computing and Computer-Assisted Intervention (MICCAI) 2024.
                                <br />
                                <p>

                                    

                                    
                                        <a class="btn btn-sm" data-bs-toggle="collapse" href="#abstractconvex_seg_miccai" role="button" aria-expanded="false" aria-controls="abstractconvex_seg_miccai" id="pub-page-btn-font">Abstract</a>
                                    

                                    
                                        <a type="button" class="btn btn-sm" href="../publications/MICCAI_24/convex_seg_miccai_24.pdf" target="_blank" id="pub-page-btn-font">Article</a>
                                    

                                    

                                    

                                    

                                    

                                   
                                    
                                        <a class="btn btn-sm" data-bs-toggle="collapse" href="#bibconvex_seg_miccai" role="button" aria-expanded="false" aria-controls="bibconvex_seg_miccai" id="pub-page-btn-font">Bibtex</a>
                                    
                                   
                                </p>
                                
                                
                                    <div class="collapse" id="abstractconvex_seg_miccai">
                                        <div class="card card-body" align="justify" style="color:  rgb(0, 136, 255); ">
                                            Image segmentation often involves objects of interest that are biologically known to be convex shaped. While typical deep-neural-networks (DNNs) for object segmentation ignore object properties relating to shape, the DNNs that employ shape information fail to enforce hard constraints on shape. We design a brand-new DNN framework that guarantees convexity of the output object-segment by leveraging fundamental geometrical insights into the boundaries of convex-shaped objects. Moreover, we design our framework to build on typical existing DNNs for per-pixel segmentation, while maintaining simplicity in loss-term formulation and maintaining frugality in model size and training time. Results using six publicly available datasets demonstrates that our DNN framework, with little overheads, provides significant benefits in the robust segmentation of convex objects in out-of-distribution images.
                                        </div>
                                    </div>
                                

                                
                                    <div class="collapse" id="bibconvex_seg_miccai">
                                        <div class="card card-body" align="justify" style="color:  rgb(0, 136, 255); ">
                                            <object data="../publications/MICCAI_24/convex_seg_miccai_24.txt" width="100%"></object>
                                        </div>
                                    </div>
                                

                                
                                
                            </div>
                        </div>
                    </div>


                



                    <div class="row g-0">
                        <div class="col-md-4 text-center my-4 px-2">
                            <img src="../publications/RV_PBS/rv_pbs.jpg" width="100%" style="box-shadow: 4px 4px 8px #888" class="center" />
                        </div>
                        <div class="col-md-8 my-4">
                            <div class="card-body">
                                <h5 class="card-title">
                                    <span id="bold_id">Advancing instance segmentation and WBC classification in peripheral blood smear through domain adaptation - A study on PBC and the novel RV-PBS datasets</span>
                                </h5>
                                <span id="bold_id"> Jimut Bahan Pal</span>, Aniket Bhattacharyea, <strong><a href="http://narendrapur.rkmvu.ac.in/wp-content/uploads/2020/09/Dr.-Debasis-Bandyopadhyay-Banerjee-CV.pdf" target="_blank"> Debasis Banerjee</a></strong> and <strong><a href="https://cs.rkmvu.ac.in/~tamal/" target="_blank" alt="Tamal's RKMVERI Website"> Tamal </a> <a href="http://cs.rkmvu.ac.in/~tamal/" target="_blank" alt="Tamal's RKMVERI Website"> Maharaj </a> </strong>
                                <br />
                                Expert Systems With Applications. (<span id="bold_id">2024</span>). <br /> <a style="color:rgb(217, 61, 61);" id="bold_id" href="https://github.com/Jimut123/RV-PBS" target="_blank"> Find the Novel RV-PBS dataset here</a>.
                                <br />
                                <p>

                                    

                                    
                                        <a class="btn btn-sm" data-bs-toggle="collapse" href="#abstractrv_pbs" role="button" aria-expanded="false" aria-controls="abstractrv_pbs" id="pub-page-btn-font">Abstract</a>
                                    

                                    
                                        <a type="button" class="btn btn-sm" href="../publications/RV_PBS/rv_pbs_paper.pdf" target="_blank" id="pub-page-btn-font">Article</a>
                                    

                                    

                                    
                                        <a class="btn btn-sm" href="../publications/RV_PBS/thesis_presentation.pdf" target="_blank" id="pub-page-btn-font">Slide</a>
                                    

                                    

                                    
                                        <a class="btn btn-sm" href="https://github.com/Jimut123/cellseg" target="_blank" id="pub-page-btn-font">Code</a>
                                    

                                   
                                    
                                        <a class="btn btn-sm" data-bs-toggle="collapse" href="#bibrv_pbs" role="button" aria-expanded="false" aria-controls="bibrv_pbs" id="pub-page-btn-font">Bibtex</a>
                                    
                                   
                                </p>
                                
                                
                                    <div class="collapse" id="abstractrv_pbs">
                                        <div class="card card-body" align="justify" style="color:  rgb(0, 136, 255); ">
                                            Automating blood cell counting and detection from smear slides holds significant potential for aiding doctors in disease diagnosis through blood tests. However, existing literature has not adequately addressed using whole slide data in this context. This study introduces the novel RV-PBS dataset, comprising ten distinct peripheral blood smear classes, each featuring multiple multi-class White Blood Cells per slide, specifically designed, for instance segmentation benchmarks. While conventional instance segmentation models like Mask R-CNN exhibit promising results in segmenting medical artifact instances, they face challenges in scenarios with limited samples and class imbalances within the dataset. This challenge prompted us to explore innovative techniques such as domain adaptation using a similar dataset to enhance the classification accuracy of Mask R-CNN, a novel approach in the domain of medical image analysis. Our study has successfully established a comprehensive pipeline capable of segmenting, detecting, and classifying blood samples from slides, striking an optimal balance between computational complexity and accurate classification of medical artifacts. This advancement enables precise cell counting and classification, facilitating doctors in refining their diagnostic analyses.
                                        </div>
                                    </div>
                                

                                
                                    <div class="collapse" id="bibrv_pbs">
                                        <div class="card card-body" align="justify" style="color:  rgb(0, 136, 255); ">
                                            <object data="../publications/RV_PBS/pal_2024_rvpbs.txt" width="100%"></object>
                                        </div>
                                    </div>
                                

                                
                                
                            </div>
                        </div>
                    </div>


                



                    <div class="row g-0">
                        <div class="col-md-4 text-center my-4 px-2">
                            <img src="../publications/BMSAN/bmsan.jpg" width="100%" style="box-shadow: 4px 4px 8px #888" class="center" />
                        </div>
                        <div class="col-md-8 my-4">
                            <div class="card-body">
                                <h5 class="card-title">
                                    <span id="bold_id">Improving Multi Scale Attention Networks - Bayesian Optimization for Segmenting medical images</span>
                                </h5>
                                <span id="bold_id"> Jimut Bahan Pal </span> and <strong><a href="https://web.archive.org/web/20200624004219/http://www2.eng.ox.ac.uk/civil/efm/people/dripta-sarkar" target="_blank"> Dripta Mj </a></strong>
                                <br />
                                The Imaging Science Journal. (<span id="bold_id">2023</span>)
                                <br />
                                <p>

                                    

                                    
                                        <a class="btn btn-sm" data-bs-toggle="collapse" href="#abstractbmsan" role="button" aria-expanded="false" aria-controls="abstractbmsan" id="pub-page-btn-font">Abstract</a>
                                    

                                    
                                        <a type="button" class="btn btn-sm" href="../publications/BMSAN/bmsan_paper.pdf" target="_blank" id="pub-page-btn-font">Article</a>
                                    

                                    

                                    

                                    

                                    
                                        <a class="btn btn-sm" href="https://github.com/Jimut123/bmsan" target="_blank" id="pub-page-btn-font">Code</a>
                                    

                                   
                                    
                                        <a class="btn btn-sm" data-bs-toggle="collapse" href="#bibbmsan" role="button" aria-expanded="false" aria-controls="bibbmsan" id="pub-page-btn-font">Bibtex</a>
                                    
                                   
                                </p>
                                
                                
                                    <div class="collapse" id="abstractbmsan">
                                        <div class="card card-body" align="justify" style="color:  rgb(0, 136, 255); ">
                                            Current deep learning based image segmentation methods are notable for their use of large number of parameters and extensive computational resources in training. There is a persistent need for more efficient flexible systems without compromising on precision. This work proposes a novel model that combines the best of deep learning and probabilistic machine learning to segment a wide variety of medical image datasets with state-of-the-art accuracy and limited resources. The approach benefits from the introduction of new diverse attention modules that serve multiple purposes including capturing of relevant information at different scales. These proposed attention modules are generic and can potentially be used with other architectures to boost performance. In addition, Bayesian optimization is employed to tune multi-scale weight hyperparameters of the model. The architecture combined with one of the proposed novel attention modules and tuned hyperparameters achieves the best results in segmenting ISIC 2017, LUNGS, NERVE, Skin Lesion, and CHEST datasets. Finally, the explainability of the network is analyzed by visualizing the feature map learned from the attention modules.
                                        </div>
                                    </div>
                                

                                
                                    <div class="collapse" id="bibbmsan">
                                        <div class="card card-body" align="justify" style="color:  rgb(0, 136, 255); ">
                                            <object data="../publications/BMSAN/bmsan.txt" width="100%"></object>
                                        </div>
                                    </div>
                                

                                
                                
                            </div>
                        </div>
                    </div>


                



                    <div class="row g-0">
                        <div class="col-md-4 text-center my-4 px-2">
                            <img src="../publications/BMIC/bmic.png" width="100%" style="box-shadow: 4px 4px 8px #888" class="center" />
                        </div>
                        <div class="col-md-8 my-4">
                            <div class="card-body">
                                <h5 class="card-title">
                                    <span id="bold_id">Biomedical image analysis competitions - The state of current participation practice</span>
                                </h5>
                                Matthias Eisenmann, Annika Reinke, ... <span id="bold_id"> Jimut Bahan Pal </span> ... Lena Maier-Hein
                                <br />
                                arXiv. (<span id="bold_id">2022</span>)
                                <br />
                                <p>

                                    
                                        <a class="btn btn-sm" data-bs-toggle="collapse" href="#authors_list_bigbmic" role="button" aria-expanded="false" aria-controls="authors_list_bigbmic" id="pub-page-btn-font">Authors</a>
                                    

                                    
                                        <a class="btn btn-sm" data-bs-toggle="collapse" href="#abstractbmic" role="button" aria-expanded="false" aria-controls="abstractbmic" id="pub-page-btn-font">Abstract</a>
                                    

                                    
                                        <a type="button" class="btn btn-sm" href="https://arxiv.org/abs/2212.08568" target="_blank" id="pub-page-btn-font">Article</a>
                                    

                                    

                                    

                                    

                                    

                                   
                                    
                                        <a class="btn btn-sm" data-bs-toggle="collapse" href="#bibbmic" role="button" aria-expanded="false" aria-controls="bibbmic" id="pub-page-btn-font">Bibtex</a>
                                    
                                   
                                </p>
                                
                                
                                    <div class="collapse" id="abstractbmic">
                                        <div class="card card-body" align="justify" style="color:  rgb(0, 136, 255); ">
                                            The number of international benchmarking competitions is steadily increasing in various fields of machine learning (ML) research and practice. This holds especially true for the field of biomedical image analysis, for which dozens of competitions are organized each year. So far, however, little is known about the common practice as well as bottlenecks faced by the community in tackling the research questions posed. To shed light on the status quo of algorithm development for biomedical imaging analysis, we designed an international survey that was issued to all participants of challenges conducted in conjunction with the IEEE International Symposium on Biomedical Imaging (ISBI) and the International Conference on Medical Image Computing and Computer Assisted Intervention (MICCAI) in the year 2021 (n = 80 competitions in total). Besides questions pertaining to general information on the team and the tackled tasks, the survey covered participants‚Äô expertise and working environments, their chosen strategies, as well as algorithm characteristics. A median of 72% challenge participants took part in the survey. According to our results, knowledge exchange was the primary incentive (70%) for participation, while the reception of prize money played only a minor role (16%). While a median of 80 working hours was spent on method development, a large portion of participants stated that they did not have enough time for method development (32%). Surprisingly, only 25% perceived the infrastructure to be a bottleneck. Overall, 94% of all solutions were deep learning-based. Of these, 84% were based on standard architectures. 43% of the respondents reported that the data samples (e.g., images) were too large to be processed at once. This was most commonly addressed by patch-based training (69%), downsampling (37%), and solving 3D analysis tasks as a series of 2D tasks. KSurprisingly, k-fold cross-validation on the training set was performed by only 37% of the participants and only 50% of the participants performed ensembling based on multiple identical models (61%) or heterogeneous models (39%). 48% of the respondents applied postprocessing steps.
                                        </div>
                                    </div>
                                

                                
                                    <div class="collapse" id="bibbmic">
                                        <div class="card card-body" align="justify" style="color:  rgb(0, 136, 255); ">
                                            <object data="../publications/BMIC/bmic_arxiv.txt" width="100%"></object>
                                        </div>
                                    </div>
                                

                                
                                    <div class="collapse" id="authors_list_bigbmic">
                                        <div class="card card-body" align="justify" style="color:  rgb(0, 136, 255); ">
                                            Matthias Eisenmann, Annika Reinke, Vivienn Weru, Minu Dietlinde Tizabi, Fabian Isensee, Tim J. Adler, Patrick Godau, Veronika Cheplygina, Michal Kozubek, Sharib Ali, Anubha Gupta, Jan Kybic, Alison Noble, Carlos Ortiz de Sol√≥rzano, Samiksha Pachade, Caroline Petitjean, Daniel Sage, Donglai Wei, Elizabeth Wilden, Deepak Alapatt, Vincent Andrearczyk, Ujjwal Baid, Spyridon Bakas, Niranjan Balu, Sophia Bano, Vivek Singh Bawa, Jorge Bernal, Sebastian Bodenstedt, Alessandro Casella, Jinwook Choi, Olivier Commowick, Marie Daum, Adrien Depeursinge, Reuben Dorent, Jan Egger, Hannah Eichhorn, Sandy Engelhardt, Melanie Ganz, Gabriel Girard, Lasse Hansen, Mattias Heinrich, Nicholas Heller, Alessa Hering, Arnaud Huaulm√©, Hyunjeong Kim, Bennett Landman, Hongwei Bran Li, Jianning Li, Jun Ma, Anne Martel, Carlos Mart√≠n-Isla, Bjoern Menze, Chinedu Innocent Nwoye, Valentin Oreiller, Nicolas Padoy, Sarthak Pati, Kelly Payette, Carole Sudre, Kimberlin van Wijnen, Armine Vardazaryan, Tom Vercauteren, Martin Wagner, Chuanbo Wang, Moi Hoon Yap, Zeyun Yu, Chun Yuan, Maximilian Zenk, Aneeq Zia, David Zimmerer, Rina Bao, Chanyeol Choi, Andrew Cohen, Oleh Dzyubachyk, Adrian Galdran, Tianyuan Gan, Tianqi Guo, Pradyumna Gupta, Mahmood Haithami, Edward Ho, Ikbeom Jang, Zhili Li, Zhengbo Luo, Filip Lux, Sokratis Makrogiannis, Dominik M√ºller, Young-tack Oh, Subeen Pang, Constantin Pape, Gorkem Polat, Charlotte Rosalie Reed, Kanghyun Ryu, Tim Scherr, Vajira Thambawita, Haoyu Wang, Xinliang Wang, Kele Xu, Hung Yeh, Doyeob Yeo, Yixuan Yuan, Yan Zeng , Xin Zhao, Julian Abbing, Jannes Adam, Nagesh Adluru, Niklas Agethen, Salman Ahmed, Yasmina Al Khalil, Mireia Aleny√†, Esa Alhoniemi, Chengyang An, Talha Anwar, Tewodros Weldebirhan Arega, Netanell Avisdris, Dogu Baran Aydogan, Yingbin Bai, Maria Baldeon Calisto, Berke Doga Basaran, Marcel Beetz, Cheng Bian, Hao Bian, Kevin Blansit, Louise Bloch, Robert Bohnsack, Sara Bosticardo, Jack Breen, Mikael Brudfors, Raphael Br√ºngel, Mariano Cabezas, Alberto Cacciola, Zhiwei Chen, Yucong Chen, Daniel Tianming Chen, Minjeong Cho, Min-Kook Choi, Chuantao Xie Chuantao Xie, Dana Cobzas, Julien Cohen-Adad, Jorge Corral Acero, Sujit Kumar Das, Marcela de Oliveira, Hanqiu Deng, Guiming Dong, Lars Doorenbos, Cory Efird, Di Fan, Mehdi Fatan Serj, Alexandre Fenneteau, Lucas Fidon, Patryk Filipiak, Ren√© Finzel, Nuno R. Freitas, Christoph M. Friedrich, Mitchell Fulton, Finn Gaida, Francesco Galati, Christoforos Galazis, Chang Hee Gan, Zheyao Gao, Shengbo Gao, Matej Gazda, Beerend Gerats, Neil Getty, Adam Gibicar, Ryan Gifford, Sajan Gohil, Maria Grammatikopoulou, Daniel Grzech, Orhun G√ºley, Timo G√ºnnemann, Chunxu Guo, Sylvain Guy, Heonjin Ha, Luyi Han, Il Song Han, Ali Hatamizadeh, Tian He, Jimin Heo, Sebastian Hitziger, SeulGi Hong, SeungBum Hong, Rian Huang, Ziyan Huang, Markus Huellebrand, Stephan Huschauer, Mustaffa Hussain, Tomoo Inubushi, Ece Isik Polat, Mojtaba Jafaritadi, SeongHun Jeong, Bailiang Jian, Yuanhong Jiang, Zhifan Jiang, Yueming Jin, Smriti Joshi, Abdolrahim Kadkhodamohammadi, Reda Abdellah Kamraoui, Inha Kang, Junghwa Kang, Davood Karimi, April Khademi, Muhammad Irfan Khan, Suleiman A. Khan, Rishab Khantwal, Kwang-Ju Kim, Timothy Kline, Satoshi Kondo, Elina Kontio, Adrian Krenzer, Artem Kroviakov, Hugo Kuijf, Satyadwyoom Kumar, Francesco La Rosa, Abhi Lad, Doohee Lee, Minho Lee, Chiara Lena, Hao Li, Ling Li, Xingyu Li, Fuyuan Liao, KuanLun Liao, Arlindo Limede Oliveira, Chaonan Lin, Shan Lin, Akis Linardos, Marius George Linguraru, Han Liu, Tao Liu, Di Liu, Yanling Liu, Jo√£o Louren√ßo-Silva, Jingpei Lu, Jiangshan Lu, Imanol Luengo, Christina B. Lund, Huan Minh Luu, Yi Lv, Yi Lv, Uzay Macar, Leon Maechler, Sina Mansour L., Kenji Marshall, Moona Mazher, Richard McKinley, Alfonso Medela, Felix Meissen, Mingyuan Meng, Dylan Miller, Seyed Hossein Mirjahanmardi, Arnab Mishra, Samir Mitha, Hassan Mohy-ud-Din, Tony Chi Wing Mok, Gowtham Krishnan Murugesan, Enamundram Naga Karthik, Sahil Nalawade, Jakub Nalepa, Mohamed Naser, Ramin Nateghi, Hammad Naveed, Quang-Minh Nguyen, Cuong Nguyen Quoc, Brennan Nichyporuk, Bruno Oliveira, David Owen, Jimut Bahan Pal, Junwen Pan, Wentao Pan, Winnie Pang, Bogyu Park, Vivek Pawar, Kamlesh Pawar, Michael Peven, Lena Philipp, Tomasz Pieciak, Szymon Plotka, Marcel Plutat, Fattaneh Pourakpour, Domen Prelo≈ænik, Kumaradevan Punithakumar, Abdul Qayyum, Sandro Queir√≥s, Arman Rahmim, Salar Razavi, Jintao Ren, Mina Rezaei, Jonathan Adam Rico, ZunHyan Rieu, Markus Rink, Johannes Roth, Yusely Ruiz-Gonzalez, Numan Saeed, Anindo Saha, Mostafa Salem, Ricardo Sanchez-Matilla, Kurt Schilling, Wei Shao, Zhiqiang Shen, Ruize Shi, Pengcheng Shi, Daniel Sobotka, Th√©odore Soulier, Bella Specktor Fadida, Danail Stoyanov, Timothy Sum Hon Mun, Xiaowu Sun, Rong Tao, Franz Thaler, Antoine Th√©berge, Felix Thielke, Helena Torres, Kareem A. Wahid, Jiacheng Wang, YiFei Wang, Wei Wang, Xiong Wang, Jianhui Wen, Ning Wen, Marek Wodzinski, Ye Wu, Fangfang Xia, Tianqi Xiang, Chen Xiaofei, Lizhan Xu, Tingting Xue, Yuxuan Yang, Lin Yang, Kai Yao, Huifeng Yao, Amirsaeed Yazdani, Michael Yip, Hwanseung Yoo, Fereshteh Yousefirizi, Shunkai Yu, Lei Yu, Jonathan Zamora, Ramy Ashraf Zeineldin, Dewen Zeng, Jianpeng Zhang, Bokai Zhang, Jiapeng Zhang, Fan Zhang, Huahong Zhang, Zhongchen Zhao, Zixuan Zhao, Jiachen Zhao, Can Zhao, Qingshuo Zheng, Yuheng Zhi, Ziqi Zhou, Baosheng Zou, Klaus Maier-Hein, Paul F. J√§ger, Annette Kopp-Schneider, Lena Maier-Hein
                                        </div>
                                    </div>
                                
                                
                            </div>
                        </div>
                    </div>


                



                    <div class="row g-0">
                        <div class="col-md-4 text-center my-4 px-2">
                            <img src="../publications/MICCAI_QUBIQ_21/qubiq_21.jpg" width="100%" style="box-shadow: 4px 4px 8px #888" class="center" />
                        </div>
                        <div class="col-md-8 my-4">
                            <div class="card-body">
                                <h5 class="card-title">
                                    <span id="bold_id">Holistic network for quantifying uncertainties in medical images</span>
                                </h5>
                                <span id="bold_id"> Jimut Bahan Pal </span>
                                <br />
                                International MICCAI Brainlesion Workshop, BrainLes 2021, Brainlesion, Glioma, Multiple Sclerosis, Stroke and Traumatic Brain Injuries. (<span id="bold_id">2022</span>)
                                <br />
                                <p>

                                    

                                    
                                        <a class="btn btn-sm" data-bs-toggle="collapse" href="#abstractmiccai_qubiq_21" role="button" aria-expanded="false" aria-controls="abstractmiccai_qubiq_21" id="pub-page-btn-font">Abstract</a>
                                    

                                    
                                        <a type="button" class="btn btn-sm" href="https://link.springer.com/chapter/10.1007/978-3-031-09002-8_49" target="_blank" id="pub-page-btn-font">Article</a>
                                    

                                    

                                    
                                        <a class="btn btn-sm" href="../publications/MICCAI_QUBIQ_21/Jimut_Bahan_Pal_QUBIQ_MICCAI.pdf" target="_blank" id="pub-page-btn-font">Slide</a>
                                    

                                    
                                        <a class="btn btn-sm" href="https://www.youtube.com/watch?v=AaVvNG-ihMU" target="_blank" id="pub-page-btn-font">Video</a>
                                    

                                    
                                        <a class="btn btn-sm" href="https://github.com/Jimut123/MICCAI_QUBIQ_21" target="_blank" id="pub-page-btn-font">Code</a>
                                    

                                   
                                    
                                        <a class="btn btn-sm" data-bs-toggle="collapse" href="#bibmiccai_qubiq_21" role="button" aria-expanded="false" aria-controls="bibmiccai_qubiq_21" id="pub-page-btn-font">Bibtex</a>
                                    
                                   
                                </p>
                                
                                
                                    <div class="collapse" id="abstractmiccai_qubiq_21">
                                        <div class="card card-body" align="justify" style="color:  rgb(0, 136, 255); ">
                                            Variability in delineation is an inherent property for segmenting medical imagery, when images are annotated by a variety of expert annotators. Previous methods have used adversarial training, Monte-Carlo sampling, and dropouts, which might sometimes produce a wide range of segmentation masks that differ from the styles of mask produced by a set of expert annotators. State-of-the-art method uses multiple U-Nets to capture the individual delineations, but it is computationally demanding. To mitigate this problem, a holistic network containing N-Encoder and N-Decoder is proposed, which could individually model the variability of delineation produced by the expert annotators. This will help to create segmentation masks for different tasks of the same dataset through a single network by learning the common features of multiple Encoders via a common channel and passing those features to Decoder. These create one segmentation mask. All the masks are calculated by using weighted loss at each end of the Decoders that show excellent results for some datasets.
                                        </div>
                                    </div>
                                

                                
                                    <div class="collapse" id="bibmiccai_qubiq_21">
                                        <div class="card card-body" align="justify" style="color:  rgb(0, 136, 255); ">
                                            <object data="../publications/MICCAI_QUBIQ_21/miccai_qubiq_21.txt" width="100%"></object>
                                        </div>
                                    </div>
                                

                                
                                
                            </div>
                        </div>
                    </div>


                



                    <div class="row g-0">
                        <div class="col-md-4 text-center my-4 px-2">
                            <img src="../publications/CXR_19/cxr_19.jpg" width="100%" style="box-shadow: 4px 4px 8px #888" class="center" />
                        </div>
                        <div class="col-md-8 my-4">
                            <div class="card-body">
                                <h5 class="card-title">
                                    <span id="bold_id">Classifying Chest X-Ray COVID-19 images via Transfer Learning</span>
                                </h5>
                                <span id="bold_id"> Jimut Bahan Pal </span> and <strong><a href="https://nlach.github.io/" target="_blank"> Nilayan Paul </a></strong>
                                <br />
                                2021 Ethics and Explainability for Responsible Data Science (EE-RDS), published in IEEE Xplore. (<span id="bold_id">2021</span>)
                                <br />
                                <p>

                                    

                                    
                                        <a class="btn btn-sm" data-bs-toggle="collapse" href="#abstractcxr_19" role="button" aria-expanded="false" aria-controls="abstractcxr_19" id="pub-page-btn-font">Abstract</a>
                                    

                                    
                                        <a type="button" class="btn btn-sm" href="https://ieeexplore.ieee.org/document/9708580" target="_blank" id="pub-page-btn-font">Article</a>
                                    

                                    

                                    
                                        <a class="btn btn-sm" href="../publications/CXR_19/CXR_COVID_19_slide.pdf" target="_blank" id="pub-page-btn-font">Slide</a>
                                    

                                    
                                        <a class="btn btn-sm" href="https://www.youtube.com/watch?v=27ixHn6SP_4" target="_blank" id="pub-page-btn-font">Video</a>
                                    

                                    
                                        <a class="btn btn-sm" href="https://github.com/Jimut123/CXR_Covid-19" target="_blank" id="pub-page-btn-font">Code</a>
                                    

                                   
                                    
                                        <a class="btn btn-sm" data-bs-toggle="collapse" href="#bibcxr_19" role="button" aria-expanded="false" aria-controls="bibcxr_19" id="pub-page-btn-font">Bibtex</a>
                                    
                                   
                                </p>
                                
                                
                                    <div class="collapse" id="abstractcxr_19">
                                        <div class="card card-body" align="justify" style="color:  rgb(0, 136, 255); ">
                                            The internal behavior of Deep Neural Network architectures can be difficult to interpret. Certain architectures achieve impressive feats in a particular dataset while failing to show comparable performance in other datasets. Developing an architecture that performs well on a dataset can be a time-consuming affair and computationally intensive process. This study explains the effect of transfer learning by fine-tuning already available state-of-the-art architectures in different datasets and using them to classify Chest X-Ray images with high accuracy. Using transfer learning helps the model learn problem-specific features in a short period. It further shows that different models perform differently in a particular setting for a dataset. Ablation studies show that a combination of smaller structures that gives an overall better result may not give the best result in the combined model. In addition, the ‚Äúbelief‚Äù of the model for selecting a particular class is visualized in this study.
                                        </div>
                                    </div>
                                

                                
                                    <div class="collapse" id="bibcxr_19">
                                        <div class="card card-body" align="justify" style="color:  rgb(0, 136, 255); ">
                                            <object data="../publications/CXR_19/9708580.txt" width="100%"></object>
                                        </div>
                                    </div>
                                

                                
                                
                            </div>
                        </div>
                    </div>


                

 </div>
</div>


<div id="front-page-font">
This material is presented to ensure timely dissemination of scholarly and technical work. 
Copyright and all rights therein are retained by authors or by other copyright holders. 
All persons copying this information are expected to adhere to the terms and constraints invoked by each author's copyright. 
In most cases, these works may not be reposted without the explicit permission of the copyright holder.
</div>

<br />


</div>


      <br><br>
      
    </div>

  


  <!-- Footer -->
  <footer class="footer page-footer font-small pt-1">
    <div  align="center">
      
          <!-- Copyright -->
          <div class="footer-copyright" style="color: rgb(217, 61, 61);"> 2019-2025
              <a href="https://github.com/Jimut123" style="color: rgb(217, 61, 61);"> Copyright ¬© Jimut Bahan Pal</a>
          </div>
          <!-- Copyright -->
    </div>
  </footer>
  <!-- Footer -->



</body>
</html>
<style>
.footer{
  position: fixed;
  bottom: 0;
  width: 100%;

}
</style>


<script>
  var preloader = document.getElementById('loading');
  function myFunction() { 
      preloader.style.display = 'none';
  }
</script>